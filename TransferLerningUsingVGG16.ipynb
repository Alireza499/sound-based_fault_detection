{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1825e83a",
   "metadata": {},
   "source": [
    "## import python-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4448bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import glob\n",
    "from tensorflow import keras\n",
    "from keras.layers.core import Dense \n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1454ae",
   "metadata": {},
   "source": [
    "gc(garbage collector) managing memory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "febecc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68822a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(30)   # used for random choice from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d4ee4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\project_jamalian\\image\\model\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.getcwd()  #corrent directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeba08f",
   "metadata": {},
   "source": [
    "## Loading images and labels\n",
    "#### first collecting paths to all the normal and abnormal mlspectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2496c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_files_path = []  \n",
    "for filename in glob.glob(f'{root_dir}/**/normals/*.png', recursive=True): # all normals path\n",
    "    normal_files_path.append(filename)\n",
    "    \n",
    "abnormal_files_path = []\n",
    "for filename in glob.glob(f'{root_dir}/**/abnormals/*.png', recursive=True): # all abnormals path\n",
    "    abnormal_files_path.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a7a47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of all normals: 44157\n",
      "count of all abnormals: 8848\n"
     ]
    }
   ],
   "source": [
    "print(f'count of all normals: {len(normal_files_path)}' )\n",
    "print(f'count of all abnormals: {len(abnormal_files_path)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd15cd06",
   "metadata": {},
   "source": [
    "#### As it is shown below with an example, we can access machine type and ab and fileName thorough names of folders that spectograms are saved in. this will be used in saving detail of each spectogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b373cbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normal_files_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-9ed2b581b2e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmachine_type\u001b[0m \u001b[1;33m=\u001b[0m   \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_files_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdb\u001b[0m           \u001b[1;33m=\u001b[0m   \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_files_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfileName\u001b[0m     \u001b[1;33m=\u001b[0m   \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_files_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmachine_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normal_files_path' is not defined"
     ]
    }
   ],
   "source": [
    "machine_type =   os.path.split(os.path.split(os.path.split(os.path.split(normal_files_path[0])[0])[0])[0])[1]\n",
    "db           =   os.path.split(os.path.split(os.path.split(normal_files_path[0])[0])[0])[1]\n",
    "fileName     =   os.path.split(normal_files_path[0])[1]\n",
    "\n",
    "print(machine_type)\n",
    "print(db)\n",
    "print(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6a1f09",
   "metadata": {},
   "source": [
    "### selecting subset of dataset:\n",
    "\n",
    "number of spectograms in base dataset:\n",
    "\n",
    "    normals  : 44157\n",
    "    \n",
    "    abnormals: 8848\n",
    "        \n",
    "But due to shortage of hardware, \n",
    "\n",
    "    normals  : 8000\n",
    "    \n",
    "    abnormals: 1000\n",
    "\n",
    "will be select randomly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91867eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_scale = 50     # down scaling images (in percent)\n",
    "\n",
    "numberOfabnormalsInDataset = 1000  \n",
    "numberOfnormalsInDataset = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555b5a9",
   "metadata": {},
   "source": [
    "### creating X and y:\n",
    "Reading images -->  Save as numpy in X -->  Save Respective y -->  Save Respective detail ( machine_type & db & fileName )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1129f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [] # TARGET, actual value (abnormal = 1 , normal = 0)\n",
    "X = [] # FEATURES, spectograms (input images)\n",
    "\n",
    "detail = [] #machine_type & db & fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ffb5bbb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normal_files_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-445903bec696>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnormals_spectrograms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_files_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumberOfnormalsInDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#select randomly from paths.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmachine_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normal_files_path' is not defined"
     ]
    }
   ],
   "source": [
    "#normals:\n",
    "normals_spectrograms=[]\n",
    "for image_path in random.choices(normal_files_path, k=numberOfnormalsInDataset): #select randomly from paths.\n",
    "    try:\n",
    "        machine_type = os.path.split(os.path.split(os.path.split(os.path.split(image_path)[0])[0])[0])[1]\n",
    "        db = os.path.split(os.path.split(os.path.split(image_path)[0])[0])[1]\n",
    "        file_name = os.path.split(image_path)[1]   \n",
    "\n",
    "\n",
    "        image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        width = int(image.shape[1] * resize_scale / 100)\n",
    "        height = int(image.shape[0] * resize_scale / 100)\n",
    "        dim = (width, height)\n",
    "        image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)  #down sizing images (memory)\n",
    "\n",
    "\n",
    "        image= np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255                          # normalaizing the data  (divide by maximum)\n",
    "        X.append(image)                       # adding the image to features\n",
    "        normals_spectrograms.append(image)\n",
    "        tmp = [machine_type, db, file_name]\n",
    "        detail.append(tmp)                   # saving detail\n",
    "        y.append(0) #normal                  # save Target\n",
    "    except:\n",
    "        print(image_path) #in case of occuring a error in reading file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10eb0b28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'abnormal_files_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-d917739d8928>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mabnormals_spectrograms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabnormal_files_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumberOfabnormalsInDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#select randomly from paths.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmachine_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'abnormal_files_path' is not defined"
     ]
    }
   ],
   "source": [
    "#abnormals:\n",
    "abnormals_spectrograms=[]\n",
    "for image_path in random.choices(abnormal_files_path, k=numberOfabnormalsInDataset): #select randomly from paths.\n",
    "    try:\n",
    "        machine_type = os.path.split(os.path.split(os.path.split(os.path.split(image_path)[0])[0])[0])[1]\n",
    "        db = os.path.split(os.path.split(os.path.split(image_path)[0])[0])[1]\n",
    "        file_name = os.path.split(image_path)[1]   \n",
    "\n",
    "\n",
    "        image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        width = int(image.shape[1] * resize_scale / 100)\n",
    "        height = int(image.shape[0] * resize_scale / 100)\n",
    "        dim = (width, height)\n",
    "        image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA) #down sizing images (memory)\n",
    "\n",
    "\n",
    "        image= np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255                                        # normalaizing the data  (divide by maximum)\n",
    "        X.append(image)                                     # adding the image to features\n",
    "        abnormals_spectrograms.append(image)\n",
    "        tmp = [machine_type, db, file_name]\n",
    "        detail.append(tmp)                                  # saving detail\n",
    "        y.append(1) #abnormal                               # save Target\n",
    "    except:\n",
    "        print(image_path)    #in case of occuring a error in reading file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222eb264",
   "metadata": {},
   "source": [
    "### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "459edcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n",
      "======================================================================\n",
      "0\n",
      "======================================================================\n",
      "['fan', '6db', '3888.png']\n"
     ]
    }
   ],
   "source": [
    "print(X[5])\n",
    "print(\"======================================================================\")\n",
    "print(y[5])\n",
    "print(\"======================================================================\")\n",
    "print(detail[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50971884",
   "metadata": {},
   "source": [
    "### saving numpys to save time in future attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78bd66a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"normals_spectrograms.npy\", normals_spectrograms)\n",
    "#normals_spectrograms = np.load(\"normals_spectrograms.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5194f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"abnormals_spectrograms.npy\", abnormals_spectrograms)\n",
    "#abnormals_spectrograms = np.load(\"abnormals_spectrograms.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dee11df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"features.npy\", X)\n",
    "#X = np.load(\"features.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0814e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"target.npy\", y)\n",
    "#y = np.load(\"target.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "617e9266",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"detail.npy\", detail)\n",
    "#detail = np.load(\"detail.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "096e76ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del normal_files_path           #free up memory\n",
    "del abnormal_files_path\n",
    "gc.collect()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "432e1f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000,)\n",
      "(9000, 144, 216, 3)\n"
     ]
    }
   ],
   "source": [
    "X =np.array(X)\n",
    "y =np.array(y)\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d677568",
   "metadata": {},
   "source": [
    "# split Dataset:\n",
    "\n",
    "20% Test data\n",
    "\n",
    "80% train data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f00a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentForTest = 20\n",
    "# train_X      = X[:len(X)*(100-percentForTest)]\n",
    "# train_y      = y[:len(X)*(100-percentForTest)]\n",
    "# train_detail = detail[:len(X)*(100-percentForTest)]\n",
    "\n",
    "# test_X       = X[len(X)*(100-percentForTest):]\n",
    "# test_y       = y[len(X)*(100-percentForTest):]\n",
    "# test_detail  = detail[len(X)*(100-percentForTest):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75976266",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 641. MiB for an array with shape (1800, 144, 216, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-70d18d02a497>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetail_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetail_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetail\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2441\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2443\u001b[1;33m     return list(\n\u001b[0m\u001b[0;32m   2444\u001b[0m         chain.from_iterable(\n\u001b[0;32m   2445\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2443\u001b[0m     return list(\n\u001b[0;32m   2444\u001b[0m         chain.from_iterable(\n\u001b[1;32m-> 2445\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2446\u001b[0m         )\n\u001b[0;32m   2447\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_pandas_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 641. MiB for an array with shape (1800, 144, 216, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=4)\n",
    "_, _, detail_train, detail_test = train_test_split(X, detail, test_size=0.20, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5efa21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 144, 216, 3)\n",
      "(1800, 144, 216, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c19b4d",
   "metadata": {},
   "source": [
    "# Transfer learning with vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780dfbf4",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/transfer-learning-with-vgg16-and-keras-50ea161580b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "390fdd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16 \n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=X_train[0].shape)  # customizing input \n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "## Preprocessing input\n",
    "X_train = preprocess_input(x_train) \n",
    "y_train = preprocess_input(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6667257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 144, 216, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 144, 216, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 144, 216, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 72, 108, 64)       0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 72, 108, 128)      73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 72, 108, 128)      147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 36, 54, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 36, 54, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 36, 54, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 36, 54, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 27, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 27, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 27, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 27, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 13, 512)        0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 13, 512)        2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 13, 512)        2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 13, 512)        2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 6, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7973e99",
   "metadata": {},
   "source": [
    "### Addtinal layers to base model(VGG16) used for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a2d07c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "flatten_layer = layers.Flatten()                             # transform to n * 1\n",
    "dense_layer_1 = layers.Dense(50, activation='relu')\n",
    "dense_layer_2 = layers.Dense(20, activation='relu')\n",
    "prediction_layer = layers.Dense(1, activation='sigmoid')     # it is a binary clasification hence sigmoid and not softmax\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense_layer_1,\n",
    "    dense_layer_2,\n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72c47937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y = np.asarray(y).astype('int').reshape((-1,1))\n",
    "# test_y = np.asarray(y).astype('int').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b2e5e5",
   "metadata": {},
   "source": [
    "<a href=\"https://en.wikipedia.org/wiki/Early_stopping\"> EarlyStopping </a>   is a form of regularization used to avoid   overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db1b1397",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-d4dfee50bd12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m# 20% of train data will be used for validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
    "\n",
    "r =model.fit(X_train, y_train, epochs=50, validation_split=0.2, batch_size=32, callbacks=[es]) \n",
    "# 20% of train data will be used for validation\n",
    "# if val_accuracy start to drop in epochs, training will be ended. (EarlyStopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc73070",
   "metadata": {},
   "source": [
    "### saving the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a330ac04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: H:\\project_jamalian\\image\\model/my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: H:\\project_jamalian\\image\\model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model.save(f'{root_dir}/my_model/')\n",
    "# model = load_model(f'{root_dir}/my_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24d1e0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD7CAYAAABDld6xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVWklEQVR4nO3dfXBU9b3H8c83yUIMDwUxijXlBmfuWHky6ELTmzvgQ0tF1OrIdLDiUx0Zx3u9PtxLpe206vhHHWtbLx17O2mL9Vm5qFNvpT5NodEZfAg0tCD0WhRKQCWhDcIVJGS/94/dxE3YkJNkT/aX5P2a2Tl7zvmd337POn44+e3Z/Zm7CwAQrqJCFwAAODaCGgACR1ADQOAIagAIHEENAIEjqAEgcJGC2sxuNbPNZrbJzJ4ws9K4CwMApPUY1GZ2iqR/k5R092mSiiUtirswAEBaSS/aHWdmrZLKJO0+VuMTTjjBKysr+1kaAAwf69evb3b38lz7egxqd99lZvdJ+qukg5JecveXjnVMZWWl6uvr+1QsAAxHZraju31Rhj7GS/qqpMmSPitplJktztFuiZnVm1l9U1NTf+oFAGSJ8mHilyS95+5N7t4q6RlJ/9S1kbvXunvS3ZPl5Tmv3gEAfRAlqP8qqdrMyszMJJ0naUu8ZQEA2vUY1O7+hqRVkjZI+lPmmNqY6wIAZES668Pd75B0R8y1AABy4JuJABA4ghoAAhf1Cy8AMPS5S22t0pFDnz5aD0VfL05I/3xr3ssiqAGEpyMwD0pHPpFaM8t+rUcMXk/1ve7REwlqAAMglZLaDkttn0hH2pefpLd1XR61LfuYw9GvRLsGa38Ds6hEKjlOKhkpJTLL7PWy46WS0vQjUfrp85zrOY5vX+/atjieSCWogUJKpXIHYU8B2HFMa7RA7U2/qSP5O7/uArM94MomdB+mR60fK0wHJjALZWidDYY393TItB3OBFhr+nmqtct6lDbdHXNYajvShzaHM0EYYyhacTrUikdkliOlkhHp9Y5tI6SyUVn7stt03TayS39d+sn5Wl36G2KBWSi8i8OVe/pPy9SRdJCkjkiptnSwpI5ktmeWqaz9bVn7sx9trZnju2uftb+ttY/h2UObVGu875kVZwIokXmMkIoSWeuJzHqmTWJspk1JZv8xArDbQDxGeBaP6LytqDje80fBDI+gTqUkb0sHRddlrm3tAXbUtvb17H1ZfaeOHL2t075Ujtdrf60ewrDHMM0Vhl2Cs2vbQikq6SHkuuxPlPXcJjtAi3pY7wjPXrQpSkhF3M2KwggrqB9dmP5QIWeoprKCsDchmcc/LeNUVJIJg5L0lVFx+/Muj+Ls9US6bcnIrPbFWf100779Cq8Q7YuKJbNCv9vAoBJWULcdluSZDyBGpv/ULCr+dJn9/FjbrCgrFLL3ZbZ33WbFOdoXfRo6Xbcd1b4oq56So7d1al/UTc2EF4Dcwgrqq58rdAUAEBwG3QAgcAQ1AASOoAaAwBHUABA4ghoAAhdlFvLTzKwh6/GRmd0yALUBABTh9jx3/7OkKkkys2JJuyQ9G29ZAIB2vR36OE/SNnffEUcxAICj9TaoF0l6Io5CAAC5RQ5qMxsh6WJJ/93N/iVmVm9m9U1NTfmqDwCGvd5cUc+XtMHdP8y1091r3T3p7sny8vL8VAcA6FVQXy6GPQBgwEUKajMrk/RlSc/EWw4AoKtIv57n7h9LmhBzLQCAHPhmIgAEjqAGgMAR1AAQOIIaAAJHUANA4AhqAAgcQQ0AgSOoASBwBDUABI6gBoDAEdQAEDiCGgACR1ADQOAIagAIHEENAIEjqAEgcAQ1AAQu6lRc48xslZltNbMtZvbFuAsDAKRFmopL0n9KesHdF5rZCEllMdYEAMjSY1Cb2VhJcyRdI0nufljS4XjLAgC0izL0caqkJkkPmtkfzOwXZjaqayMzW2Jm9WZW39TUlPdCAWC4ihLUJZLOlPRf7j5T0v9JWta1kbvXunvS3ZPl5eV5LhMAhq8oQd0oqdHd38isr1I6uAEAA6DHoHb3DyTtNLPTMpvOk/R2rFUBADpEvevjJkmPZe74eFfStfGVBADIFimo3b1BUjLeUgAAufDNRAAIHEENAIEjqAEgcAQ1AASOoAaAwBHUABA4ghoAAkdQA0DgCGoACBxBDQCBI6gBIHAENQAEjqAGgMAR1AAQOIIaAAJHUANA4CJNHGBm2yXtl9Qm6Yi7M4kAAAyQqFNxSdI57t4cWyUAgJwY+gCAwEUNapf0kpmtN7MlcRYEAOgs6tBHjbvvNrMTJb1sZlvdvS67QSbAl0jSpEmT8lwmAAxfka6o3X13ZrlH0rOSZudoU+vuSXdPlpeX57dKABjGegxqMxtlZmPan0uaJ2lT3IUBANKiDH2cJOlZM2tv/7i7vxBrVQCADj0Gtbu/K+mMAagFAJADt+cBQOAIagAIHEENAIEjqAEgcAQ1AASOoAaAwBHUABA4ghoAAkdQA0DgejNxAACotbVVjY2NOnToUKFLGZRKS0tVUVGhRCIR+RiCGkCvNDY2asyYMaqsrFTmN4AQkbtr7969amxs1OTJkyMfx9AHgF45dOiQJkyYQEj3gZlpwoQJvf5rhKAG0GuEdN/15b0jqAEMGi0tLfrpT3/ap2MvuOACtbS0RG5/55136r777uvTa+UbQQ1g0DhWULe1tR3z2NWrV2vcuHExVBU/ghrAoLFs2TJt27ZNVVVVWrp0qdauXatzzjlHX//61zV9+nRJ0iWXXKKzzjpLU6dOVW1tbcexlZWVam5u1vbt23X66afr+uuv19SpUzVv3jwdPHjwmK/b0NCg6upqzZgxQ5deeqn+/ve/S5KWL1+uKVOmaMaMGVq0aJEk6fe//72qqqpUVVWlmTNnav/+/f0+b+76ANBnd/3PZr29+6O89jnls2N1x0VTc+675557tGnTJjU0NEiS1q5dqzfffFObNm3quItixYoVOv7443Xw4EHNmjVLl112mSZMmNCpn3feeUdPPPGEfv7zn+trX/uann76aS1evLjbmq666ir95Cc/0dy5c/W9731Pd911l+6//37dc889eu+99zRy5MiOYZX77rtPDzzwgGpqanTgwAGVlpb2+z2JfEVtZsVm9gcz+02/XxUA8mT27NmdbnVbvny5zjjjDFVXV2vnzp165513jjpm8uTJqqqqkiSdddZZ2r59e7f979u3Ty0tLZo7d64k6eqrr1ZdXZ0kacaMGbriiiv06KOPqqQkfd1bU1Oj2267TcuXL1dLS0vH9v7oTQ83S9oiaWy/XxXAkNDdle9AGjVqVMfztWvX6pVXXtG6detUVlams88+O+etcCNHjux4Xlxc3OPQR3eef/551dXV6bnnntPdd9+tzZs3a9myZVqwYIFWr16t6upqvfLKK/r85z/fp/7bRbqiNrMKSQsk/aJfrwYA/TBmzJhjjvnu27dP48ePV1lZmbZu3arXX3+936/5mc98RuPHj9err74qSXrkkUc0d+5cpVIp7dy5U+ecc47uvfdetbS06MCBA9q2bZumT5+u22+/XclkUlu3bu13DVGvqO+X9E1JY/r9igDQRxMmTFBNTY2mTZum+fPna8GCBZ32n3/++frZz36mGTNm6LTTTlN1dXVeXvehhx7SDTfcoI8//linnnqqHnzwQbW1tWnx4sXat2+f3F233nqrxo0bp+9+97tas2aNiouLNWXKFM2fP7/fr2/ufuwGZhdKusDdbzSzsyX9h7tfmKPdEklLJGnSpEln7dixo9/FAQjPli1bdPrppxe6jEEt13toZuvdPZmrfZShjxpJF5vZdklPSjrXzB7t2sjda9096e7J8vLy3lcOAMipx6B292+5e4W7V0paJOl37t79fSwAgLziCy8AELhe3eDn7mslrY2lEgBATlxRA0DgCGoACBxBDWBIGz16dK+2h4igBoDAEdQABo3bb7+90+9R33nnnfrhD3+oAwcO6LzzztOZZ56p6dOn69e//nXkPt1dS5cu1bRp0zR9+nQ99dRTkqT3339fc+bMUVVVlaZNm6ZXX31VbW1tuuaaazra/vjHP877OebCz5wC6LvfLpM++FN++5w4XZp/T85dixYt0i233KIbb7xRkrRy5Uq98MILKi0t1bPPPquxY8equblZ1dXVuvjiiyNNe/XMM8+ooaFBGzduVHNzs2bNmqU5c+bo8ccf11e+8hV95zvfUVtbmz7++GM1NDRo165d2rRpkyT1asaY/iCoAQwaM2fO1J49e7R79241NTVp/PjxmjRpklpbW/Xtb39bdXV1Kioq0q5du/Thhx9q4sSJPfb52muv6fLLL1dxcbFOOukkzZ07V2+99ZZmzZqlb3zjG2ptbdUll1yiqqoqnXrqqXr33Xd10003acGCBZo3b94AnDVBDaA/urnyjdPChQu1atUqffDBBx2zqjz22GNqamrS+vXrlUgkVFlZGXmm7+5+72jOnDmqq6vT888/ryuvvFJLly7VVVddpY0bN+rFF1/UAw88oJUrV2rFihV5O7fuMEYNYFBZtGiRnnzySa1atUoLFy6UlP550xNPPFGJREJr1qxRb34Ubs6cOXrqqafU1tampqYm1dXVafbs2dqxY4dOPPFEXX/99bruuuu0YcMGNTc3K5VK6bLLLtPdd9+tDRs2xHWanXBFDWBQmTp1qvbv369TTjlFJ598siTpiiuu0EUXXaRkMqmqqqpe/VD/pZdeqnXr1umMM86Qmenee+/VxIkT9dBDD+kHP/iBEomERo8erYcffli7du3Stddeq1QqJUn6/ve/H8s5dtXjz5z2RTKZ9Pr6+rz3C6Dw+JnT/ovjZ04BAAVEUANA4AhqAAgcQQ2g1+L4bGu46Mt7R1AD6JXS0lLt3buXsO4Dd9fevXtVWlraq+O4PQ9Ar1RUVKixsVFNTU2FLmVQKi0tVUVFRa+O6TGozaxUUp2kkZn2q9z9jj5VCGDQSyQSmjx5cqHLGFaiXFF/Iulcdz9gZglJr5nZb9399ZhrAwAoQlB7eiDqQGY1kXkwOAUAAyTSh4lmVmxmDZL2SHrZ3d+ItSoAQIdIQe3ube5eJalC0mwzm9a1jZktMbN6M6vnQwYAyJ9e3Z7n7i2S1ko6P8e+WndPunuyvLw8P9UBAHoOajMrN7NxmefHSfqSpK0x1wUAyIhy18fJkh4ys2Klg32lu/8m3rIAAO2i3PXxR0kzB6AWAEAOfIUcAAJHUANA4AhqAAgcQQ0AgSOoASBwBDUABI6gBoDAEdQAEDiCGgACR1ADQOAIagAIHEENAIEjqAEgcAQ1AASOoAaAwBHUABA4ghoAAhdlzsTPmdkaM9tiZpvN7OaBKAwAkBZlzsQjkv7d3TeY2RhJ683sZXd/O+baAACKcEXt7u+7+4bM8/2Stkg6Je7CAABpvRqjNrNKpSe6fSPHviVmVm9m9U1NTXkqDwAQOajNbLSkpyXd4u4fdd3v7rXunnT3ZHl5eT5rBIBhLVJQm1lC6ZB+zN2fibckAEC2KHd9mKRfStri7j+KvyQAQLYoV9Q1kq6UdK6ZNWQeF8RcFwAgo8fb89z9NUk2ALUAAHLgm4kAEDiCGgACR1ADQOAIagAIHEENAIEjqAEgcAQ1AASOoAaAwBHUABA4ghoAAkdQA0DgCGoACBxBDQCBI6gBIHAENQAEjqAGgMAR1AAQuChzJq4wsz1mtmkgCgIAdBblivpXks6PuQ4AQDd6DGp3r5P0twGoBQCQQ97GqM1siZnVm1l9U1NTvroFgGEvb0Ht7rXunnT3ZHl5eb66BYBhj7s+ACBwBDUABC7K7XlPSFon6TQzazSz6+IvCwDQrqSnBu5++UAUAgDIjaEPAAgcQQ0AgSOoASBwBDUABI6gBoDAEdQAEDiCGgACR1ADQOAIagAIHEENAIEjqAEgcAQ1AASOoAaAwBHUABA4ghoAAkdQA0DgIgW1mZ1vZn82s7+Y2bK4iwIAfCrKVFzFkh6QNF/SFEmXm9mUuAsDAKT1OBWXpNmS/uLu70qSmT0p6auS3s53Meu27ZXLVWSmIjOZSUUmWfu6lLXdVFQkmSyrTef93S079VXUvi3d16dtPu3TzPJ9qgAQWZSgPkXSzqz1RklfiKOYa3/1pg61puLout+y/xHI/kehPfTNpKKi7PXsNun17H8Eisyk9j4LfXIA8mJ82QitvOGLee83SlDnyhE/qpHZEklLJGnSpEl9KuaR676gtpQr5S53HXOZcsnbl8ped6VS6QLT7dv3dV7vtk9l1lPd9J3pK3u9vY9OfSuznsrRd6fjjnorAQxSY0sTsfQbJagbJX0ua71C0u6ujdy9VlKtJCWTyT6lz6zK4/tyGAAMaVHu+nhL0j+a2WQzGyFpkaTn4i0LANCuxytqdz9iZv8q6UVJxZJWuPvm2CsDAEiKNvQhd18taXXMtQAAcuCbiQAQOIIaAAJHUANA4AhqAAgcQQ0AgbM4vhlnZk2SdvTx8BMkNeexnMGAcx76htv5Spxzb/2Du5fn2hFLUPeHmdW7e7LQdQwkznnoG27nK3HO+cTQBwAEjqAGgMCFGNS1hS6gADjnoW+4na/EOedNcGPUAIDOQryiBgBkCSaoh+MEuma2wsz2mNmmQtcyEMzsc2a2xsy2mNlmM7u50DXFzcxKzexNM9uYOee7Cl3TQDGzYjP7g5n9ptC1DAQz225mfzKzBjOrz2vfIQx9ZCbQ/V9JX1Z6ooK3JF3u7nmflzEkZjZH0gFJD7v7tELXEzczO1nSye6+wczGSFov6ZKh/N/Z0hNujnL3A2aWkPSapJvd/fUClxY7M7tNUlLSWHe/sND1xM3MtktKunve7x0P5Yq6YwJddz8sqX0C3SHN3esk/a3QdQwUd3/f3Tdknu+XtEXpOTmHLE87kFlNZB6FvzqKmZlVSFog6ReFrmUoCCWoc02gO6T/Bx7uzKxS0kxJbxS4lNhlhgAaJO2R9LK7D/lzlnS/pG9KCnO26ni4pJfMbH1mDtm8CSWoI02gi6HBzEZLelrSLe7+UaHriZu7t7l7ldLzjc42syE9zGVmF0ra4+7rC13LAKtx9zMlzZf0L5mhzbwIJagjTaCLwS8zTvu0pMfc/ZlC1zOQ3L1F0lpJ5xe2ktjVSLo4M2b7pKRzzezRwpYUP3ffnVnukfSs0kO6eRFKUDOB7jCQ+WDtl5K2uPuPCl3PQDCzcjMbl3l+nKQvSdpa0KJi5u7fcvcKd69U+v/l37n74gKXFSszG5X5gFxmNkrSPEl5u5sriKB29yOS2ifQ3SJp5XCYQNfMnpC0TtJpZtZoZtcVuqaY1Ui6UukrrIbM44JCFxWzkyWtMbM/Kn1B8rK7D4vb1YaZkyS9ZmYbJb0p6Xl3fyFfnQdxex4AoHtBXFEDALpHUANA4AhqAAgcQQ0AgSOoASBwBDUABI6gBoDAEdQAELj/B+y5Oh2zGPU9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# accuracies\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
